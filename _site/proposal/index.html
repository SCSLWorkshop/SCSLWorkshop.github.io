<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Workshop description | SCSL'25</title>
    <meta name="author" content="Workshop on  Spurious Correlation and Shortcut Learning" />
    <meta name="description" content="" />


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous" />

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light" />

    <!-- Styles -->
    
    <link rel="shortcut icon" href="/assets/img//assets/img/cell"/>
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="http://localhost:4000/proposal/">
    
    <!-- Dark Mode -->
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav sticky-bottom-footer">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="/">SCSL'25</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">About</a>
              </li>
              

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/schedule/">Schedule</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/submissions/">Call for Papers</a>
              </li>
              <li class="nav-item active">
                <a class="nav-link" href="/proposal/">Workshop description<span class="sr-only">(current)</span></a>
              </li>
            </ul>
          </div>
        </div>
      </nav>

    </header>


    <!-- Content -->
    <div class="container mt-5">
      <!-- page.html -->
        <div class="post">

          <header class="post-header">
            <h1 class="post-title">Workshop description</h1>
            <p class="post-description"></p>
          </header>

          <article>
            <p>Over the last decade, deep learning has brought about astonishing improvements in computer vision,
signal processing, language modeling and beyond. This unprecedented success is due to a huge
collective endeavor to build large-scale models. As a result, the remarkable performance of these
models has largely surpassed our understanding of them.</p>

<p>An established approach to analyzing these models is to build a bottom-up theory of deep learning,
where rigorous proofs are devised to explain deep networks. However, these models usually are only
tractable when they are oversimplified. Although valuable progress has been made on that front, the
complexity of real high-dimensional data and deep network architectures used in practice make these
models resistant to traditional mathematical analysis. Hence, many aspects remain mysterious and
our understanding of their success and failure modes remains very limited.</p>

<p>The aim of this workshop is to promote a complementary approach to further our understanding
of deep learning, through the lens of the scientific method. This approach uses carefully designed
experiments in order to answer precise questions about how and why deep learning works. The
scientific method has been used successfully in the past to validate or falsify hypotheses, (e.g., deep
networks generalize because they cannot fit random labels [<a href="https://openreview.net/pdf?id=Sy8gdB9xx" target="_blank" rel="noopener noreferrer">Zhang et al</a>]), challenge common assumptions (e.g.,
deep networks are robust to imperceptible input perturbations [<a href="https://arxiv.org/pdf/1312.6199" target="_blank" rel="noopener noreferrer">Szegedy et al</a>]), or reveal empirical regularities
(e.g., discovering scaling laws [<a href="https://arxiv.org/pdf/2001.08361" target="_blank" rel="noopener noreferrer">Kaplan et al</a>]). These well-known examples all crucially rely on controlled
experiments, and constitute an important part of our current understanding of deep learning.</p>

<p>Although these works aimed neither to improve the state-of-the-art nor to prove theorems, they
have had a profound impact, spurring many follow-up theoretical and applied works. Indeed, such
results serve the theory of deep learning by grounding it with empirical observations (e.g., training
occurs on the edge of stability [<a href="https://openreview.net/pdf?id=jh-rTtvkGeM" target="_blank" rel="noopener noreferrer">Cohen et al</a>]) or formulating conjectures (e.g., the lottery ticket hypothesis
[<a href="https://openreview.net/pdf?id=rJl-b3RcF7" target="_blank" rel="noopener noreferrer">Frankle &amp; Carbin</a>]). Simultaneously, they lead to practical improvements by informing engineering decisions, e.g.,
compute-optimal scaling [<a href="https://proceedings.neurips.cc/paper_files/paper/2022/file/c1e2faff6f588870935f114ebe04a3e5-Paper-Conference.pdf" target="_blank" rel="noopener noreferrer">Hoffmann et al</a>], and spurring new research directions, e.g., adversarial robustness [<a href="https://arxiv.org/pdf/1412.5068" target="_blank" rel="noopener noreferrer">Gu &amp; Rigazio</a>].
Thus, we believe, that this workshop will be of interest to both theoretical and applied communities.</p>

<p>Despite their significant impact, these studies have been largely underexplored and underappreciated. 
While the criteria for assessing quantitative contributions such as improving state-of-the-art
performance or for proving rigorous theorems are more clear-cut, assessing the significance of
contributions within this category are still developing and forming. Our workshop would offer a
venue for studies that fall outside the standard acceptance criteria yet have a high impact potential.
Thus, our workshop significantly differs from and complements past workshops accepted at main
machine learning conferences.</p>

<p>The scientific study of deep learning is currently scattered across several subfields, including incontext learning in transformers, generalization properties of generative models, inductive biases
of learning algorithms, (mechanistic) interpretability, empirical studies of loss landscapes, training
dynamics, and learned weights and representations. This workshop will facilitate communication and
collaboration across subfields by building a community centered around a common approach.</p>

          </article>

        </div>
    </div>

    <!-- Footer -->    <footer class="sticky-bottom mt-5">
      <div class="container">
        Â© Copyright 2024 Workshop on  Spurious Correlation and Shortcut Learning. Last updated: October 12, 2024.
      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js"></script><!-- Load Common JS -->
  <script defer src="/assets/js/common.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    
    

  </body>
</html>
