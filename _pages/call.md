---
layout: page
permalink: /submissions/
title: Call for Papers
description:
nav: true
nav_order: 3
---

Reliance on spurious correlations due to simplicity bias is a well-known pitfall of deep learning models. This issue stems from the statistical nature of deep learning algorithms and their inductive biases at all stages, including data preprocessing, architectures, and optimization. Therefore, spurious correlations and shortcut learning are fundamental and common practical problems across all branches of AI. The foundational nature and widespread occurrence of reliance on spurious correlations and shortcut learning make it an important research topic and a gateway to understanding how deep models learn patterns and the underlying mechanisms responsible for their effectiveness and generalization. This workshop aims to address two aspects of this phenomenon: its foundations and potential solutions.

## Topics
The topics of interest for the workshop include, but are not limited to, the following:

* Introducing new spurious correlation benchmarks for various fields and modalities, including multimodal data (image, text, audio, video, graph, time series, etc.)  
  * Examining foundational large language models (LLMs) and large multimodal models (LMMs) in terms of robustness to spurious correlations  
  * Creating new datasets to evaluate the robustness of multi-modal models  
  * Developing new benchmarks focusing on different types of features as shortcuts  
  * Constructing new robustness benchmarks for various applications (medical, social, industrial, etc.)  
  * Designing new reinforcement learning environments to study spurious correlations  
  * Presenting new real-world scenarios and benchmarks that challenge reliance on spurious correlations and shortcut learning  
* Proposing new robustification methods  
  * Finding solutions for the efficient robustification of LLMs and LMMs  
  * Introducing new robustification methods for various paradigms, such as reinforcement learning, contrastive learning, and self-supervised learning  
  * Proposing new algorithms for causal representation learning  
  * Investigating novel solutions for robustness to spurious correlations in less-explored areas, such as optimization algorithms and data gathering and preprocessing schemes  
* Exploring the foundations of spurious correlations and shortcut learning  
  * Presenting mathematical formulations that describe the issue and its origins  
  * Studying the role of widely used gradient-descent-based optimization methods in reliance on shortcuts and improvement solutions  
  * Exploring the effect of shortcuts and spurious features on the loss landscape


## Important Dates

*   Submission Deadline: February XX '25 (Anywhere on Earth)
*   Acceptance Notification: March XX '25 (Anywhere on Earth)
<!-- *   Camera-Ready Deadline for Accepted Submissions: `TBD` -->

## Submission Details

To ensure your submission is considered, please adhere to the following guidelines:

* **Formatting Instructions**: Submissions are limited to 4 pages, with unlimited additional pages for references and appendices. **Please use [this LaTeX style files template](/assets/files/styles.zip)**.
* **Reviews**: The review process will be double-blind. **All submissions must be anonymized**. Submissions that breach anonymity will be desk-rejected.
* **Dual Submission Policy**: If the submission was accepted at prior conferences, journal, or workshops (including Neurips 2024), it should be extended and include new results to be considered for acceptance. Papers that are currently under review are welcome to be submitted.
* There will be no proceedings for the venue. We will post the list of accepted papers on the workshop website. In addition, accepted submissions will be made public on OpenReview.
* Submissions will be reviewed on OpenReview: [submission page](https://openreview.net/group?id=NeurIPS.cc/2024/Workshop/SciForDL).
* To apply for financial assistance fill out this [form](https://forms.gle/mANcM9ZkS7q7BCof7). 

## Questions

If you have any questions, please do not hesitate to contact us at [scienceofdl.workshop.2024@gmail.com](mailto:scienceofdl.workshop.2024@gmail.com).
